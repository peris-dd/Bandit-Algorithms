
## Bandit Algorithms

**UCL - COMP0029 - 05/2022**

<div align = "justify">This project explores the trade-off between exploration and exploitation in unknown environments, through multi-armed bandit (MAB) algorithms. The aim of this investigation is to
introduce standard MAB algorithms, and subsequently implement various improvements presented in the literature, so as to enable efficient sharing of information and improved selection of optimal actions
in a network of users. The focus is on deterministic and oblivious adversarial environments in the bandit setting, and the main algorithms evaluated are: EXP3, Multi-Task Hedge and GABA-I.</div>
